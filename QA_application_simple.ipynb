{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u25YO4ZxYQ5N"
      },
      "outputs": [],
      "source": [
        "pip install openai langchain huggingface_hub sentence_transformers faiss-cpu chroma tiktoken python-magic unstructured colab-env chromadb pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.evaluation.qa import QAGenerateChain\n",
        "from langchain.evaluation.qa import QAEvalChain\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n"
      ],
      "metadata": {
        "id": "OrjqmIduaCb6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OPENAI_API_KEY = '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' # Mom's key"
      ],
      "metadata": {
        "id": "Qb7i_k6qbQIg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = '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' # Mom's key"
      ],
      "metadata": {
        "id": "TfqiDqlcQgwt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF loader"
      ],
      "metadata": {
        "id": "9X3AIogHfV35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/HCL/ChatConversationAnalysis/Check1/Angry customer directed to higher mangement.pdf\")\n",
        "\n",
        "#Load the document by calling loader.load()\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "x8x3ul68Yany"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL loader"
      ],
      "metadata": {
        "id": "4nfczzCSfYyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"urls = ['https://www.cellcom.com/planDetails.html?navtype=personal&service=calling&type=family&plan=unlimited_plus' ]\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "loaders = UnstructuredURLLoader(urls=urls)\n",
        "pages = loaders.load()\"\"\""
      ],
      "metadata": {
        "id": "3w8TjTeOZN47"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(pages)\n"
      ],
      "metadata": {
        "id": "KYer6_0JZSiq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8ks3ICY0LDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Now you have {len(texts)} documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtGioXzqZot4",
        "outputId": "4732dda0-8b0e-41a6-8e80-587f69f098eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 4 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up embeddings and vector store\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "vectorstore = Chroma.from_documents(texts, embeddings)\n"
      ],
      "metadata": {
        "id": "qeGVHK-4aQkZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up retrieval QA chain\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "llm=llm,\n",
        "chain_type=\"stuff\",\n",
        "retriever=vectorstore.as_retriever(),\n",
        "verbose=True,\n",
        "chain_type_kwargs={\n",
        "\"document_separator\": \"<<<<>>>>>\"\n",
        "}\n",
        ")\n"
      ],
      "metadata": {
        "id": "6iHXod41bFJO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is the cost of two smart phones \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "a78391cf-cac3-4102-9ead-778defe14510",
        "id": "r7EmBD-kh4qN"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't have enough information to answer your question.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is the cost of two standard smart phones  \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "ffKBTAz6KRts",
        "outputId": "f61a4b53-e775-4a4d-98bd-d7a0ebb7c5bd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The cost of two standard smartphones would be $60 per month.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is considered as an international message? \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "bc2d36f7-2908-4a43-cb4c-5cf273320735",
        "id": "qSyUVFUuiOSi"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided context, there is no information about international messaging. Therefore, I don't have the answer to your question.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From chat dataset"
      ],
      "metadata": {
        "id": "anCOCXC-m__X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is this whole document about?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "p43J-ETTfIb1",
        "outputId": "a176ffb6-e505-4e05-ac40-46982fa5db28"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This document is a conversation between a customer and a higher management representative, as well as a separate conversation between a customer and an agent, regarding a problem with a product not functioning as advertised. The customer expresses frustration and dissatisfaction with the company's support and threatens to switch to a competitor. The higher management representative and agent apologize for the inconvenience and assure the customer that they will work towards resolving the issue promptly.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"How does the agent sounds? Is the agent rude or helpful? \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "8rRuuRLmnPgF",
        "outputId": "235f3d18-2cb1-4ff5-a1c0-cbbca4cce918"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The agent in this conversation sounds helpful. They apologize for any inconvenience, take the customer's feedback seriously, and offer to assist further. They also apologize for the inconvenience the customer has faced and offer to connect them to higher management to address their concerns.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"How does the agent sounds? Is the agent rude or helpful? \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "jMmwkqmTnbTQ",
        "outputId": "08b8f278-9bec-4dcb-faf9-e6fda64e6451"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The agent initially sounds apologetic and understanding, trying to address the customer's concerns and offer assistance. However, as the conversation progresses, the agent's responses become more repetitive and lack specific solutions, which could be seen as unhelpful to the customer.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what are the requirements to find words per minute from the chat provided in the document \"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "wOIqtZukQGNK",
        "outputId": "5a1adc3d-659b-4fff-9c81-bbcb2c44f4cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To find the words per minute from the chat provided in the document, you would need to manually count the number of words in the chat and then divide that by the total time it took to have the conversation. This calculation would give you the average words per minute for that specific chat.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-V6KUJLbQ-So"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}