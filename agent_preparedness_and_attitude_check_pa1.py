# -*- coding: utf-8 -*-
"""Agent_preparedness_and_attitude_check_PA1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lV_hCu019QvIcCv1MiUxe-Sdeg8S2hjy
"""



!pip install openai langchain unstructured sentence_transformers PyPDF2 --upgrade tiktoken -q chromadb -q gradio -q

# @title Key
import os
os.environ["HUGGINGFACEHUB_API_TOKEN"] ="OpenAI_API_key"
os.environ["OPENAI_API_KEY"] = "Hugging_FACE_KEY"

import pandas as pd
import re
import pandas as pd
import tiktoken
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain.prompts import PromptTemplate
from langchain.indexes.vectorstore import VectorstoreIndexCreator
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.document_loaders import TextLoader
from langchain.document_loaders import UnstructuredURLLoader
from urllib.parse import urlparse
from langchain import HuggingFaceHub
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.evaluation.qa import QAGenerateChain
from langchain.evaluation.qa import QAEvalChain

from dotenv import load_dotenv, find_dotenv
import PyPDF2
from PyPDF2 import PdfReader
from typing_extensions import Concatenate
from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader

import gradio as gr
import pandas as pd
import re
import pandas as pd
import tiktoken
from langchain.chat_models import ChatOpenAI
# from langchain.evaluation.criteria import LabeledCriteriaEvalChain
# from langchain.chat_models import ChatAnthropic
# from langchain.evaluation.criteria import CriteriaEvalChain
from langchain.evaluation import load_evaluator, EvaluatorType

import time
import json
import gradio as gr
import pandas as pd
import re
import pandas as pd
import tiktoken
from langchain.evaluation import load_evaluator, EvaluatorType

def url_reader(url):
  loaders = UnstructuredURLLoader(urls=[url])
  data = loaders.load()
  raw_text = data[0].page_content
  # Convert text to lowercase
  raw_text = raw_text.lower()
  # Remove special characters using regular expressions
  data = re.sub(r'[^a-zA-Z0-9\s]', '', raw_text)
  encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
  list_token = encoding.encode(data)
  return data, len(list_token)


from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_chunk(data):
  text_splitter = RecursiveCharacterTextSplitter(

      chunk_size = 800,
      chunk_overlap  = 150,
  )
  texts = text_splitter.create_documents([data])

  persist_directory = 'QA_db'
  embedding = OpenAIEmbeddings()
  vectorstore = Chroma.from_documents(documents = texts,
                              embedding=embedding,
                              persist_directory=persist_directory)
  return vectorstore

def retrieval_prediction(query):

  llm = ChatOpenAI(temperature=0.0)
  embedding = OpenAIEmbeddings()
  vectorstore = Chroma(persist_directory='/content/QA_db',
                    embedding_function=embedding)
  qa = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
            verbose=True,
            chain_type_kwargs={
                "document_separator": "<<<<>>>>>"
            }
  )

  with open(query.name) as openfile:
    examples = json.load(openfile)

  # Predict answers

  results = []
  for i in range(0,len(examples)):
    predictions = qa.apply([examples[i]])
    results += predictions
    time.sleep(2)

  #save the results file as json
  save_file = open("results.json", "w")
  json.dump(results, save_file, indent = 1)
  save_file.close()

  return results

def QAeval(query):
  with open(query.name) as openfile:
    examples = json.load(openfile)
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)
  llm = ChatOpenAI(temperature=0)
  eval_chain = QAEvalChain.from_llm(llm)
  graded_outputs = eval_chain.evaluate(examples, results)
  graded_ouptuts = graded_outputs
  qaeval_res = []
  for i in range(0,len(graded_outputs)):

    try:
      qaeval_res.append((graded_outputs[i]))
    except:
      qaeval_res.append("got error")
  return qaeval_res


def final_results():
  # read the results file
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)

  evaluator = load_evaluator("labeled_score_string", llm=ChatOpenAI(model="gpt-4"))
  score_card = []
  for i in range(0,len(results)):
    try:
      eval_result = evaluator.evaluate_strings(
        prediction= results[i]['answer'],
        input=results[i]['query'],
        reference=results[i]['result'],
        )
      if eval_result['score'] ==1:
        eval_result['score'] = 0
      score_card.append(str(eval_result['score']*10))
    except:
      score_card.append("got error")
  return score_card


def attitude_check():
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)
  hh_criteria = {
      "sarcastic": "The agent's answer may be correct or may not be correct,  but giving sarcastic replies",
      "rude": "The agent's answer may be correct or may not be correct but it is rude ,offensive and unethical.",
      "impolite" : "The agent's answer may be correct or may not be correct but it is not in a respectful tone and not polite"
  }
  evaluator = load_evaluator("labeled_score_string",criteria=hh_criteria, llm=ChatOpenAI(model="gpt-4"))
  score_card = []
  reasoning = []
  for i in range(0,len(results)):
    try:
      eval_result = evaluator.evaluate_strings(
        prediction= results[i]['answer'],
        input=results[i]['query'],
        reference=results[i]['result'],
        )
      score_card.append(str(eval_result['score']))
      reasoning.append(str(eval_result['reasoning']))
    except:
      score_card.append("got error")
      reasoning.append("got error")
  return score_card, reasoning




with gr.Blocks(theme=gr.themes.Soft()) as demo:
  with gr.Tab("URL reference for customer agent conversation"):

    with gr.Row():

      with gr.Column():
        text_input_5 = gr.components.Textbox(label = "Upload the reference url website ", placeholder = "Enter your url here")
        text_input_6 = gr.components.File(label = "Enter the chat conversation")

        text_output_15 = gr.Textbox(label="Text in the URL")
        text_output_16 = gr.Textbox(label="Vectordb created at this location")
        text_output_17 = gr.Textbox(label="No of tokens for whole website")
        text_output_18 = gr.Textbox(label="Answer predictions of LLM")
        text_output_20 = gr.Textbox(label ="Results using QA evalchain, [correct/incorrect]")
        text_output_19 = gr.Textbox(label="Accuracy percentage score of the agent responses, [out of 100%] ")
        text_output_21 = gr.Textbox(label = " Attitude check score(1-10) [10 for polite, 1-impolite]")
        text_output_22 = gr.Textbox(label = "Reason for the given attitude score")

      with gr.Column():
        gr.Image("/content/sample_data/HCLTech logo.png")
        gr.Image("/content/sample_data/Celcom logo.png")

        text_button_10= gr.Button("Load the URL ")
        text_button_11 = gr.Button("Splitt_chunk_VectorDB store")
        text_button_13= gr.Button("Retrieving and predicting")
        text_button_15 = gr.Button("Result[Correct/Incorrect]")
        text_button_14 = gr.Button("Percentage match")
        text_button_16 = gr.Button("Attitude check")


  text_button_10.click(url_reader, inputs=text_input_5, outputs= [text_output_15, text_output_17])
  text_button_11.click(split_chunk, inputs=text_output_15, outputs=text_output_16)
  text_button_13.click(retrieval_prediction, inputs=text_input_6, outputs=text_output_18)
  text_button_14.click(final_results, outputs=text_output_19)
  text_button_15.click(QAeval,inputs=text_input_6,outputs=text_output_20)
  text_button_16.click(attitude_check, outputs=[text_output_21,text_output_22])

demo.launch(debug = True)



"""Cosine similarity check"""

import time
import json
import gradio as gr
import pandas as pd
import re
import pandas as pd
import tiktoken
import openai
from openai.embeddings_utils import get_embedding, cosine_similarity
from langchain.evaluation import load_evaluator, EvaluatorType

def url_reader(url):

  loaders = UnstructuredURLLoader(urls=[url])
  data = loaders.load()
  raw_text = data[0].page_content
  # Convert text to lowercase
  raw_text = raw_text.lower()
  # Remove special characters using regular expressions
  data = re.sub(r'[^a-zA-Z0-9\s]', '', raw_text)
  encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
  list_token = encoding.encode(data)
  return data, len(list_token)


from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_chunk(data):
  text_splitter = RecursiveCharacterTextSplitter(

      chunk_size = 800,
      chunk_overlap  = 150,
  )
  texts = text_splitter.create_documents([data])

  persist_directory = 'QA_db'
  embedding = OpenAIEmbeddings()
  vectorstore = Chroma.from_documents(documents = texts,
                              embedding=embedding,
                              persist_directory=persist_directory)
  return vectorstore

def retrieval_prediction(query):

  llm = ChatOpenAI(temperature=0.0)
  embedding = OpenAIEmbeddings()
  vectorstore = Chroma(persist_directory='/content/QA_db',
                    embedding_function=embedding)
  qa = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
            verbose=True,
            chain_type_kwargs={
                "document_separator": "<<<<>>>>>"
            }
  )

  with open(query.name) as openfile:
    examples = json.load(openfile)

  # Predict answers

  results = []
  for i in range(0,len(examples)):
    predictions = qa.apply([examples[i]])
    results += predictions
    time.sleep(2)

  #save the results file as json
  save_file = open("results.json", "w")
  json.dump(results, save_file, indent = 1)
  save_file.close()

  return results

def QAeval(query):
  with open(query.name) as openfile:
    examples = json.load(openfile)
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)
  llm = ChatOpenAI(temperature=0)
  eval_chain = QAEvalChain.from_llm(llm)
  graded_outputs = eval_chain.evaluate(examples, results)
  graded_ouptuts = graded_outputs
  qaeval_res = []
  for i in range(0,len(graded_outputs)):

    try:
      qaeval_res.append((graded_outputs[i]))
    except:
      qaeval_res.append("got error")
  return qaeval_res


def final_results():
  # read the results file
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)

  evaluator = load_evaluator("labeled_score_string", llm=ChatOpenAI(model="gpt-4"))
  score_card = []
  for i in range(0,len(results)):
    try:
      eval_result = evaluator.evaluate_strings(
        prediction= results[i]['answer'],
        input=results[i]['query'],
        reference=results[i]['result'],
        )
      if eval_result['score'] ==1:
        eval_result['score'] = 0
      score_card.append(str(eval_result['score']*10))
    except:
      score_card.append("got error")
  return score_card


def cosine_sim():
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)
  similarity_score = []
  for i in range(0,len(results)):
    try:
      embedding1 = get_embedding(results[i]['answer'],engine='text-embedding-ada-002')
      embedding2 = get_embedding(results[i]['result'],engine='text-embedding-ada-002')
      similarity = cosine_similarity(embedding1,embedding2)
      similarity_score.append(str(similarity))
    except:
      similarity_score.append("Got error")
  return similarity_score


def attitude_check():
  with open('/content/results.json', 'r') as openfile:
    results = json.load(openfile)
  hh_criteria = {
      "sarcastic": "The agent's answer may be correct or may not be correct,  but giving sarcastic replies",
      "rude": "The agent's answer may be correct or may not be correct but it is rude ,offensive and unethical.",
      "impolite" : "The agent's answer may be correct or may not be correct but it is not in a respectful tone and not polite"
  }
  evaluator = load_evaluator("labeled_score_string",criteria=hh_criteria, llm=ChatOpenAI(model="gpt-4"))
  score_card = []
  reasoning = []
  for i in range(0,len(results)):
    try:
      eval_result = evaluator.evaluate_strings(
        prediction= results[i]['answer'],
        input=results[i]['query'],
        reference=results[i]['result'],
        )
      score_card.append(str(eval_result['score']))
      reasoning.append(str(eval_result['reasoning']))
    except:
      score_card.append("got error")
      reasoning.append("got error")
  return score_card, reasoning




with gr.Blocks(theme=gr.themes.Soft()) as demo:
  with gr.Tab("URL reference for customer agent conversation"):

    with gr.Row():

      with gr.Column():
        text_input_5 = gr.components.Textbox(label = "Upload the reference url website ", placeholder = "Enter your url here")
        text_input_6 = gr.components.File(label = "Enter the chat conversation")

        text_output_15 = gr.Textbox(label="Text in the URL")
        text_output_16 = gr.Textbox(label="Vectordb created at this location")
        text_output_17 = gr.Textbox(label="No of tokens for whole website")
        text_output_18 = gr.Textbox(label="Answer predictions of LLM")
        text_output_20 = gr.Textbox(label ="Results using QA evalchain, [correct/incorrect]")
        text_output_19 = gr.Textbox(label="Accuracy percentage score of the agent responses, [out of 100%] ")
        text_output_21 = gr.Textbox(label = " Attitude check score(1-10) [10 for polite, 1-impolite]")
        text_output_22 = gr.Textbox(label = "Reason for the given attitude score")
        text_output_23 = gr.Textbox(label = "Cosine similarity score")

      with gr.Column():
        gr.Image("/content/sample_data/HCLTech logo.png")
        gr.Image("/content/sample_data/Celcom logo.png")

        text_button_10= gr.Button("Load the URL ")
        text_button_11 = gr.Button("Splitt_chunk_VectorDB store")
        text_button_13= gr.Button("Retrieving and predicting")
        text_button_15 = gr.Button("Result[Correct/Incorrect]")
        text_button_14 = gr.Button("Percentage match")
        text_button_16 = gr.Button("Attitude check")
        text_button_17 = gr.Button("Cosine similarity")


  text_button_10.click(url_reader, inputs=text_input_5, outputs= [text_output_15, text_output_17])
  text_button_11.click(split_chunk, inputs=text_output_15, outputs=text_output_16)
  text_button_13.click(retrieval_prediction, inputs=text_input_6, outputs=text_output_18)
  text_button_14.click(final_results, outputs=text_output_19)
  text_button_15.click(QAeval,inputs=text_input_6,outputs=text_output_20)
  text_button_16.click(attitude_check, outputs=[text_output_21,text_output_22])
  text_button_17.click(cosine_sim,outputs = text_output_23)

demo.launch(debug = True)

